{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import csv\n",
    "from textblob import TextBlob\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "import pycountry\n",
    "import re\n",
    "import string\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from PIL import Image\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from langdetect import detect\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tokens\n",
    "def getTokens():\n",
    "    credentials =[]\n",
    "    with open(\"../login.csv\", 'r') as file:\n",
    "        csvreader = csv.reader(file)\n",
    "        for row in csvreader:\n",
    "            credentials.append(row)\n",
    "    # Don't return headers\n",
    "    return credentials[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage(part,whole):\n",
    "     return 100 * float(part)/float(whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = getTokens()\n",
    "consumerKey = tokens[0]\n",
    "consumerSecret = tokens[1]\n",
    "accessToken = tokens[2]\n",
    "accessTokenSecret = tokens[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumerKey, consumerSecret)\n",
    "auth.set_access_token(accessToken, accessTokenSecret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentiment Analysis\n",
    "# keyword = input(\"Please enter keyword or hashtag to search: \")\n",
    "keyword = \"bitcoin\"\n",
    "# noOfTweet = int(input(\"Please enter how many tweets to analyze: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweepy.Cursor(api.search_tweets, q=keyword).items(100)\n",
    "positive:int = 0\n",
    "negative:int = 0\n",
    "neutral:int = 0\n",
    "polarity = 0\n",
    "tweet_list = []\n",
    "neutral_list = []\n",
    "negative_list = []\n",
    "positive_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_stopwords(text):\n",
    "    text = [word for word in text if word not in stopword]\n",
    "    return text\n",
    "\n",
    "tw_list['nonstop'] = tw_list['tokenized'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing stopwords\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    if type(tweet) == np.float:\n",
    "        return \"\"\n",
    "    temp = tweet.lower()\n",
    "    temp = re.sub(\"'\", \"\", temp) # to avoid removing contractions in english\n",
    "    temp = re.sub(\"@[A-Za-z0-9_]+\",\"\", temp)\n",
    "    temp = re.sub(\"#[A-Za-z0-9_]+\",\"\", temp)\n",
    "    temp = re.sub(r'http\\S+', '', temp)\n",
    "    temp = re.sub('[()!?]', ' ', temp)\n",
    "    temp = re.sub('\\[.*?\\]',' ', temp)\n",
    "    temp = re.sub(\"[^a-z0-9]\",\" \", temp)\n",
    "    temp = temp.split()\n",
    "    temp = [w for w in temp if not w in stopwords]\n",
    "    temp = \" \".join(word for word in temp)\n",
    "    print(temp)\n",
    "    sleep(5)\n",
    "    return temp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jerem\\AppData\\Local\\Temp\\ipykernel_5496\\1563610548.py:5: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if type(tweet) == np.float:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rt 2021 vs 2022 drawdown slightly smaller longer period looks like bottom forming\n",
      "pos = 0.153, neg = 0.0\n",
      "elon u better talking bitcoin prices\n",
      "pos = 0.293, neg = 0.0\n",
      "rt want make big difference earning money join\n",
      "pos = 0.163, neg = 0.0\n",
      "rt always enough research\n",
      "pos = 0.0, neg = 0.0\n",
      "rt fuck putin fuck zelensky fuck biden fuck nato fuck un nation states buy\n",
      "pos = 0.0, neg = 0.593\n",
      "rt showing power decentralized money forbes\n",
      "pos = 0.0, neg = 0.0\n",
      "rt exploring investor perceptions inflation hedge mornings first mover americas reports htt\n",
      "pos = 0.0, neg = 0.0\n",
      "rt typical ct like ok bitcoin didnt pump first 2 minutes invasion country wa\n",
      "pos = 0.118, neg = 0.0\n",
      "rt still perfectly track\n",
      "pos = 0.318, neg = 0.0\n",
      "rt crypto miner could raise bitcoin mining hashrate 95 new intel deal company\n",
      "pos = 0.0, neg = 0.0\n",
      "gay trans propaganda big infertility op imo\n",
      "pos = 0.0, neg = 0.154\n",
      "rt q8 trade\n",
      "pos = 0.0, neg = 0.0\n",
      "rt taikun global token coming binance smart chain\n",
      "pos = 0.13, neg = 0.0\n",
      "one best project team inspiration innovative approaches\n",
      "pos = 0.382, neg = 0.0\n",
      "3 reasons bitcoin rally back 60k despite erasing last week gains\n",
      "pos = 0.156, neg = 0.0\n",
      "bitcoin es lo mismo que bitcoin en un exchange usa monederos autocustodiados puedes usar usdt pero conside\n",
      "pos = 0.0, neg = 0.109\n",
      "rt g nayd n millet n\n",
      "pos = 0.0, neg = 0.0\n",
      "rt want make big difference earning money join\n",
      "pos = 0.163, neg = 0.0\n",
      "war buy bitcoin\n",
      "pos = 0.0, neg = 0.529\n",
      "rt\n",
      "pos = 0.0, neg = 0.0\n",
      "new working home bitcoin trading options heres little tip get\n",
      "pos = 0.0, neg = 0.0\n",
      "rt breakout\n",
      "pos = 0.0, neg = 0.0\n",
      "rt ive slowly adding friends makes easier send put hand\n",
      "pos = 0.211, neg = 0.0\n",
      "rt gm sometimes need chill let thing cafe cassis france\n",
      "pos = 0.12, neg = 0.0\n",
      "rt nice green candles never loose faith giant lot come pretty sure\n",
      "pos = 0.359, neg = 0.082\n",
      "rt fdbl providing alternative wake spotify controversy\n",
      "pos = 0.0, neg = 0.0\n",
      "rt showing power decentralized money forbes\n",
      "pos = 0.0, neg = 0.0\n",
      "il faut qu cl ture h4 au dessus des 39 8k\n",
      "pos = 0.0, neg = 0.0\n",
      "bitcoin cryptocurrency good country money loss ban cryptocurrency good black\n",
      "pos = 0.0, neg = 0.493\n",
      "still believe bitcoin\n",
      "pos = 0.0, neg = 0.0\n",
      "news wild fears chernobyl style nuclear meltdown send bitcoin lower overnight\n",
      "pos = 0.0, neg = 0.312\n",
      "rt fdbl completes phase one integration fan pass livestream platform artist republik music distribution servi\n",
      "pos = 0.113, neg = 0.0\n",
      "rt dear\n",
      "pos = 0.394, neg = 0.0\n",
      "rt crypto life\n",
      "pos = 0.0, neg = 0.0\n",
      "rt 300 000 shib coi n eki li 2 ki iye ki ba 150 000 shib coin hediye yapman z gerekenler 1 son 5 eki li e\n",
      "pos = 0.0, neg = 0.0\n",
      "rt new project mortal wars mwt mortal wars decentralized p2e game platform based binance smart chai\n",
      "pos = 0.1, neg = 0.268\n",
      "rt heres bitcoin lingo need know\n",
      "pos = 0.0, neg = 0.0\n",
      "\n",
      "pos = 0.0, neg = 0.0\n",
      "\n",
      "pos = 0.0, neg = 0.0\n",
      "totally secure safe project team active look clients\n",
      "pos = 0.33, neg = 0.0\n",
      "rt 2x 1000 paypal ou btc 2 gagnant pour participer rt follow tag un dans les tirage dans 1 h\n",
      "pos = 0.0, neg = 0.0\n",
      "rt buy lovecoin tokens using account super simple method\n",
      "pos = 0.0, neg = 0.0\n",
      "nothing expensive missed opportunity buy sekuya skuy\n",
      "pos = 0.162, neg = 0.143\n",
      "rt daily rsi forming huge symmetrical triangle began hit 33k january\n",
      "pos = 0.15, neg = 0.0\n",
      "us food chain giant shake shack offers cashback via\n",
      "pos = 0.0, neg = 0.134\n",
      "really good project amazing start\n",
      "pos = 0.333, neg = 0.0\n",
      "follow us grab monster sale meta monster sale 0 0025 weth\n",
      "pos = 0.0, neg = 0.0\n",
      "market time highs\n",
      "pos = 0.0, neg = 0.0\n",
      "rt apple co founder steve wozniak pure gold mathematics\n",
      "pos = 0.0, neg = 0.0\n",
      "rt 10 000 000 lovecoin giveaway raffle contest retweet post amp post lovecoin address comment section\n",
      "pos = 0.0, neg = 0.0\n",
      "jadore les concours et je sais que vous aussi\n",
      "pos = 0.0, neg = 0.0\n",
      "new working home bitcoin trading options heres little\n",
      "pos = 0.0, neg = 0.0\n",
      "need clarity one thing classify asset liabi\n",
      "pos = 0.245, neg = 0.0\n",
      "rt 2x 1000 paypal ou btc 2 gagnant pour participer rt follow tag un dans les tirage dans 1 h\n",
      "pos = 0.0, neg = 0.0\n",
      "rt opinion benefits mining bitcoin texas natural gas\n",
      "pos = 0.317, neg = 0.0\n",
      "rt haz rlad e itim eri ini payla yorum indekiler temel formasyonlar harmonikler psikoloj\n",
      "pos = 0.0, neg = 0.0\n",
      "shake shack big surprise bitcoin crypto fans via\n",
      "pos = 0.142, neg = 0.115\n",
      "rt gears turning alpha testing rails network well underway stay tuned exciting times ahead ht\n",
      "pos = 0.219, neg = 0.0\n",
      "rt buying bitcoin past months\n",
      "pos = 0.0, neg = 0.0\n",
      "rt presale live buy tokens lowest price prepared\n",
      "pos = 0.084, neg = 0.116\n",
      "rt mientras tanto los colonizadores digitales de bitcoin les ofrecen la tierra prometida en espacios seguros donde po\n",
      "pos = 0.0, neg = 0.0\n",
      "rt protocol experiencing marked increase market cap numbers reaching upper limit issuance f\n",
      "pos = 0.163, neg = 0.0\n",
      "wharton professor urges fed bite bullet defend us dollar warns bitcoin taking\n",
      "pos = 0.0, neg = 0.069\n",
      "2 using globally price discovery phase everyone uses btc\n",
      "pos = 0.0, neg = 0.0\n",
      "\n",
      "pos = 0.0, neg = 0.0\n",
      "rt breaking city lugano make legal tender allow citizens pay public service f\n",
      "pos = 0.143, neg = 0.059\n",
      "rt k sa vadede bir atak ilk nce ye il eni mal uan b lgeyi zorluyor grafik 1 saatlik k sa al sat\n",
      "pos = 0.0, neg = 0.0\n",
      "rt ichi ing trend reversal stables go brrrrrrr worst case see sideways fyckery\n",
      "pos = 0.0, neg = 0.17\n",
      "rt secret investing forget private key rediscover 10 years simple\n",
      "pos = 0.0, neg = 0.083\n",
      "project undoubtedly done self satisfaction like project lot working\n",
      "pos = 0.157, neg = 0.0\n",
      "una mirada tan optimista btc est en riesgo al depender de un nivel btc perdi 17 en 5 el nivel de\n",
      "pos = 0.0, neg = 0.091\n",
      "rt taikun tesla airdrop launched participate claim free 5tkt tokens click link join\n",
      "pos = 0.292, neg = 0.0\n",
      "exciting would good chat bitcoin 2022 person\n",
      "pos = 0.276, neg = 0.0\n",
      "rt ukraynaya giden bitcoin ba lar 70 milyon dolar\n",
      "pos = 0.0, neg = 0.0\n",
      "rt flash giveaway 1x 50 enter 1 follow amp 2 rt amp\n",
      "pos = 0.0, neg = 0.0\n",
      "rt note ever fallen logarithmic regression curve due catacl\n",
      "pos = 0.0, neg = 0.098\n",
      "rt less talk bitcoin great week swirgians\n",
      "pos = 0.227, neg = 0.0\n",
      "rt unity strength diverse group investors planet shared bitcoin ethereum 2010\n",
      "pos = 0.227, neg = 0.0\n",
      "rt wallet ada price around 1 50 ghost chain went 3\n",
      "pos = 0.0, neg = 0.084\n",
      "rt wont buy bitcoin buy\n",
      "pos = 0.0, neg = 0.0\n",
      "rt mientras tanto los colonizadores digitales de bitcoin les ofrecen la tierra prometida en espacios seguros donde po\n",
      "pos = 0.0, neg = 0.0\n",
      "gm serrr sekuya skuy\n",
      "pos = 0.0, neg = 0.0\n",
      "rt eki li var ekili artlar hesab z takip etmek bu tweeti retweetlemek 1 arkada n z etiketleyin 3 bluetoo\n",
      "pos = 0.0, neg = 0.0\n",
      "remember hypocrites accused china mining bitcoin early stages\n",
      "pos = 0.0, neg = 0.121\n",
      "rt feliz domingo para todos seguir estudiando lo mejor con esta tecnolog est n por venir\n",
      "pos = 0.0, neg = 0.0\n",
      "rt still perfectly track\n",
      "pos = 0.318, neg = 0.0\n",
      "jb82sv found user vault location join playing awesome\n",
      "pos = 0.247, neg = 0.0\n",
      "buy right around 50 000 cad 2 million satoshis 1000\n",
      "pos = 0.0, neg = 0.0\n",
      "rt 5 000 000 5 milyon daha da yorum g nderiyi en takip et\n",
      "pos = 0.0, neg = 0.0\n",
      "rt intel signed another miner new energy efficient mining asics hive joins jack dorseys block\n",
      "pos = 0.205, neg = 0.0\n",
      "rt inverted dominance chart textbook cup amp handle shaped inverted bitcoin dominance chart br\n",
      "pos = 0.153, neg = 0.0\n",
      "rt money frozen one click never money fixes\n",
      "pos = 0.0, neg = 0.0\n",
      "rt taikun tesla airdrop launched participate claim free 5tkt tokens click link join\n",
      "pos = 0.292, neg = 0.0\n",
      "rt send bitcoin putin ukrainians one stop\n",
      "pos = 0.0, neg = 0.239\n",
      "like said lets use hiding capabilities seems unique af\n",
      "pos = 0.121, neg = 0.106\n",
      "rt paid 1 500 1st thought late 1 costs 1 500 000 still people\n",
      "pos = 0.0, neg = 0.0\n",
      "china massive amounts stranded low cost power gen capacity bitcoin miners us\n",
      "pos = 0.0, neg = 0.0\n",
      "rt next week bullish\n",
      "pos = 0.0, neg = 0.0\n",
      "rt 300 000 shib coi n eki li 2 ki iye ki ba 150 000 shib coin hediye yapman z gerekenler 1 son 5 eki li e\n",
      "pos = 0.0, neg = 0.0\n",
      "really good project amazing start\n",
      "pos = 0.333, neg = 0.0\n"
     ]
    }
   ],
   "source": [
    "for tweet in tweets:\n",
    "    tweet_list.append(clean_tweet(tweet.text))\n",
    "    analysis = TextBlob(tweet.text)\n",
    "    score = SentimentIntensityAnalyzer().polarity_scores(tweet.text)\n",
    "    neg = score['neg']\n",
    "    neu = score['neu']\n",
    "    pos = score['pos']\n",
    "    comp = score['compound']\n",
    "    polarity += analysis.sentiment.polarity\n",
    "    print(f'pos = {pos}, neg = {neg}')\n",
    "    if  pos < neg:\n",
    "        negative_list.append(tweet.text)\n",
    "        negative += 1\n",
    "    elif pos > neg:\n",
    "        positive_list.append(tweet.text)\n",
    "        positive += 1\n",
    "    elif pos == neg:\n",
    "        neutral_list.append(tweet.text)\n",
    "        neutral += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = percentage(positive, 100)\n",
    "negative = percentage(negative, 100)\n",
    "neutral = percentage(neutral, 100)\n",
    "polarity = percentage(polarity, 100)\n",
    "positive = format(positive, '.1f')\n",
    "negative = format(negative, '.1f')\n",
    "neutral = format(neutral, '.1f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of Tweets (Total, Positive, Negative, Neutral)\n",
    "tweet_list = pd.DataFrame(tweet_list)\n",
    "neutral_list = pd.DataFrame(neutral_list)\n",
    "negative_list = pd.DataFrame(negative_list)\n",
    "positive_list = pd.DataFrame(positive_list)\n",
    "print(f\"total number: {len(tweet_list)}\")\n",
    "print(f\"positive number: {len(positive_list)}\")\n",
    "print(f\"negative number: {len(negative_list)}\")\n",
    "print(f\"neutral number: {len(neutral_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_list.drop_duplicates(inplace = True)\n",
    "#Creating PieCart\n",
    "labels = ['Positive ['+str(positive)+'%]' , 'Neutral ['+str(neutral)+'%]','Negative ['+str(negative)+'%]']\n",
    "sizes = [positive, neutral, negative]\n",
    "colors = ['yellowgreen', 'blue','red']\n",
    "patches, texts = plt.pie(sizes,colors=colors, startangle=90)\n",
    "plt.style.use('default')\n",
    "plt.legend(labels)\n",
    "plt.title(\"Sentiment Analysis Result for keyword= \"+keyword+\"\" )\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      buna ne kadar etkileşim rt fav gelirse o kada...\n",
       "1      rûpela me ya   nûjen bû! wek guleke zer xwe b...\n",
       "2      _nft more then 2000$ in nft to gave away foll...\n",
       "3      ／\\n6カ月連続キャンペーン第2弾🎊\\n🎉#フォローrtキャンペーン 🎉\\n1,000円分...\n",
       "4                       itcoin no or never\\n👇🏾👇🏾👇🏾\\n   \n",
       "                            ...                        \n",
       "95     today we scalp longed $hbar\\n\\nentry: $0.2056...\n",
       "96     presale is live now, buy tokens for lowest pr...\n",
       "97                     _tr      _ai  _o_l_o_        …  \n",
       "98     diamondhand\\n     era shibnobi , great projec...\n",
       "99     in a gun fight, nobody wants to own the secon...\n",
       "Name: text, Length: 82, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cleaning Text (RT, Punctuation etc)\n",
    "#Creating new dataframe and new features\n",
    "tw_list = pd.DataFrame(tweet_list)\n",
    "tw_list[\"text\"] = tw_list[0]\n",
    "#Removing RT, Punctuation etc\n",
    "remove_rt = lambda x: re.sub('RT @\\w+: ',\" \",x)\n",
    "rt = lambda x: re.sub(\"(@[A-Za-z0–9]+)|(#[0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",x)\n",
    "tw_list[\"text\"] = tw_list.text.map(remove_rt).map(rt)\n",
    "tw_list[\"text\"] = tw_list.text.str.lower()\n",
    "tw_list.head(10)\n",
    "\n",
    "tw_list['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Negative, Positive, Neutral and Compound values\n",
    "tw_list[['polarity', 'subjectivity']] = tw_list['text'].apply(lambda Text: pd.Series(TextBlob(Text).sentiment))\n",
    "for index, row in tw_list['text'].iteritems():\n",
    "    score = SentimentIntensityAnalyzer().polarity_scores(row)\n",
    "    neg = score['neg']\n",
    "    neu = score['neu']\n",
    "    pos = score['pos']\n",
    "    comp = score['compound']\n",
    "    if neg > pos:\n",
    "        tw_list.loc[index, 'sentiment'] = \"negative\"\n",
    "    elif pos > neg:\n",
    "        tw_list.loc[index, 'sentiment'] = \"positive\"\n",
    "    else:\n",
    "        tw_list.loc[index, 'sentiment'] = \"neutral\"\n",
    "        tw_list.loc[index, 'neg'] = neg\n",
    "        tw_list.loc[index, 'neu'] = neu\n",
    "        tw_list.loc[index, 'pos'] = pos\n",
    "        tw_list.loc[index, 'compound'] = comp\n",
    "tw_list.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating new data frames for all sentiments (positive, negative and neutral)\n",
    "tw_list_negative = tw_list[tw_list[\"sentiment\"]==\"negative\"]\n",
    "tw_list_positive = tw_list[tw_list[\"sentiment\"]==\"positive\"]\n",
    "tw_list_neutral = tw_list[tw_list[\"sentiment\"]==\"neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_values_in_column(data,feature):\n",
    "    total=data.loc[:,feature].value_counts(dropna=False)\n",
    "    percentage=round(data.loc[:,feature].value_counts(dropna=False,normalize=True)*100,2)\n",
    "    return pd.concat([total,percentage],axis=1,keys=['Total','Percentage'])\n",
    "\n",
    "#Count_values for sentiment\n",
    "count_values_in_column(tw_list,\"sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data for Pie Chart\n",
    "pc = count_values_in_column(tw_list,\"sentiment\")\n",
    "names= pc.index\n",
    "size=pc[\"Percentage\"]\n",
    " \n",
    "# Create a circle for the center of the plot\n",
    "my_circle=plt.Circle( (0,0), 0.7, color='white')\n",
    "plt.pie(size, labels=names, colors=['green','blue','red'])\n",
    "p=plt.gcf()\n",
    "p.gca().add_artist(my_circle)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to Create Wordcloud\n",
    "def create_wordcloud(text):\n",
    "    mask = np.array(Image.open(\"cloud.png\"))\n",
    "    stopwords = set(STOPWORDS)\n",
    "    wc = WordCloud(background_color=\"white\",\n",
    "    mask = mask,\n",
    "    max_words=3000,\n",
    "    stopwords=stopwords,\n",
    "    repeat=True).generate(str(text)).to_file(\"wc.png\")\n",
    "    # wc.generate(str(text))\n",
    "    # wc.to_file(\"wc.png\")\n",
    "    print(\"Word Cloud Saved Successfully\")\n",
    "    path=\"wc.png\"\n",
    "    display(Image.open(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating wordcloud for all tweets\n",
    "create_wordcloud(tw_list[\"text\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating wordcloud for positive sentiment\n",
    "create_wordcloud(tw_list_positive[\"text\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating wordcloud for negative sentiment\n",
    "create_wordcloud(tw_list_negative[\"text\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating tweet's lenght and word count\n",
    "tw_list['text_len'] = tw_list['text'].astype(str).apply(len)\n",
    "tw_list['text_word_count'] = tw_list['text'].apply(lambda x: len(str(x).split()))\n",
    "round(pd.DataFrame(tw_list.groupby(\"sentiment\").text_len.mean()),2)\n",
    "\n",
    "tw_list['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(pd.DataFrame(tw_list.groupby(\"sentiment\").text_word_count.mean()),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Punctuation\n",
    "def remove_punct(text):\n",
    "    text = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    text = re.sub('[0–9]+', '', text)\n",
    "    return text\n",
    "\n",
    "tw_list['punct'] = tw_list['text'].apply(lambda x: remove_punct(x))\n",
    "\n",
    "tw_list['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'punct'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jerem\\Bureau\\twitter-bot\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/jerem/Bureau/twitter-bot/venv/lib/site-packages/pandas/core/indexes/base.py?line=3619'>3620</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/jerem/Bureau/twitter-bot/venv/lib/site-packages/pandas/core/indexes/base.py?line=3620'>3621</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   <a href='file:///c%3A/Users/jerem/Bureau/twitter-bot/venv/lib/site-packages/pandas/core/indexes/base.py?line=3621'>3622</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\jerem\\Bureau\\twitter-bot\\venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\jerem\\Bureau\\twitter-bot\\venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'punct'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jerem\\Bureau\\twitter-bot\\bot\\bot.ipynb Cell 25'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jerem/Bureau/twitter-bot/bot/bot.ipynb#ch0000023?line=2'>3</a>\u001b[0m     text \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mW+\u001b[39m\u001b[39m'\u001b[39m, text)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jerem/Bureau/twitter-bot/bot/bot.ipynb#ch0000023?line=3'>4</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m text\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jerem/Bureau/twitter-bot/bot/bot.ipynb#ch0000023?line=4'>5</a>\u001b[0m tw_list[\u001b[39m'\u001b[39m\u001b[39mtokenized\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m tw_list[\u001b[39m'\u001b[39;49m\u001b[39mpunct\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: tokenization(x\u001b[39m.\u001b[39mlower()))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jerem/Bureau/twitter-bot/bot/bot.ipynb#ch0000023?line=5'>6</a>\u001b[0m tw_list[\u001b[39m'\u001b[39m\u001b[39mtokenized\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\jerem\\Bureau\\twitter-bot\\venv\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/jerem/Bureau/twitter-bot/venv/lib/site-packages/pandas/core/frame.py?line=3502'>3503</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   <a href='file:///c%3A/Users/jerem/Bureau/twitter-bot/venv/lib/site-packages/pandas/core/frame.py?line=3503'>3504</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> <a href='file:///c%3A/Users/jerem/Bureau/twitter-bot/venv/lib/site-packages/pandas/core/frame.py?line=3504'>3505</a>\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   <a href='file:///c%3A/Users/jerem/Bureau/twitter-bot/venv/lib/site-packages/pandas/core/frame.py?line=3505'>3506</a>\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   <a href='file:///c%3A/Users/jerem/Bureau/twitter-bot/venv/lib/site-packages/pandas/core/frame.py?line=3506'>3507</a>\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\jerem\\Bureau\\twitter-bot\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/jerem/Bureau/twitter-bot/venv/lib/site-packages/pandas/core/indexes/base.py?line=3620'>3621</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   <a href='file:///c%3A/Users/jerem/Bureau/twitter-bot/venv/lib/site-packages/pandas/core/indexes/base.py?line=3621'>3622</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> <a href='file:///c%3A/Users/jerem/Bureau/twitter-bot/venv/lib/site-packages/pandas/core/indexes/base.py?line=3622'>3623</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/jerem/Bureau/twitter-bot/venv/lib/site-packages/pandas/core/indexes/base.py?line=3623'>3624</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/jerem/Bureau/twitter-bot/venv/lib/site-packages/pandas/core/indexes/base.py?line=3624'>3625</a>\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/jerem/Bureau/twitter-bot/venv/lib/site-packages/pandas/core/indexes/base.py?line=3625'>3626</a>\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/jerem/Bureau/twitter-bot/venv/lib/site-packages/pandas/core/indexes/base.py?line=3626'>3627</a>\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/jerem/Bureau/twitter-bot/venv/lib/site-packages/pandas/core/indexes/base.py?line=3627'>3628</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'punct'"
     ]
    }
   ],
   "source": [
    "#Appliyng tokenization\n",
    "def tokenization(text):\n",
    "    text = re.split('\\W+', text)\n",
    "    return text\n",
    "tw_list['tokenized'] = tw_list['punct'].apply(lambda x: tokenization(x.lower()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing stopwords\n",
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "def remove_stopwords(text):\n",
    "    text = [word for word in text if word not in stopword]\n",
    "    return text\n",
    "\n",
    "tw_list['nonstop'] = tw_list['tokenized'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Appliyng Stemmer\n",
    "ps = nltk.PorterStemmer()\n",
    "def stemming(text):\n",
    "    text = [ps.stem(word) for word in text]\n",
    "    return text\n",
    "tw_list['stemmed'] = tw_list['nonstop'].apply(lambda x: stemming(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning Text\n",
    "def clean_text(text):\n",
    "    text_lc = \"\".join([word.lower() for word in text if word not in string.punctuation]) # remove puntuation\n",
    "    text_rc = re.sub('[0-9]+', '', text_lc)\n",
    "    tokens = re.split('\\W+', text_rc)    # tokenization\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopword]  # remove stopwords and stemming\n",
    "    return text\n",
    "tw_list.head()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "67dd3c8b2621c6c89c7862222f9a88ce344d1328b12ab397935bd5ee8108948e"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
